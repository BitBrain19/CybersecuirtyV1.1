"""
ML-Based Malware Detection System
Detects malware using static+behavioral features
Real-time scoring with adaptive thresholds
"""

import asyncio
import json
import logging
import pickle
import uuid
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from collections import defaultdict, deque
import threading
import re

import numpy as np
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_score, recall_score, f1_score

logger = logging.getLogger(__name__)


class MalwareSeverity(str, Enum):
    """Malware threat severity"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    SUSPICIOUS = "suspicious"


class MalwareType(str, Enum):
    """Types of malware"""
    RANSOMWARE = "ransomware"
    TROJAN = "trojan"
    WORM = "worm"
    ROOTKIT = "rootkit"
    SPYWARE = "spyware"
    ADWARE = "adware"
    UNKNOWN = "unknown"


@dataclass
class ProcessEvent:
    """Represents a process execution event"""
    event_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    timestamp: datetime = field(default_factory=datetime.now)
    
    process_name: str = ""
    process_path: str = ""
    command_line: str = ""
    process_id: int = 0
    parent_process_id: int = 0
    parent_process_name: str = ""
    
    user: str = ""
    hash_md5: str = ""
    hash_sha256: str = ""
    
    # Dynamic behavior
    registry_accesses: List[str] = field(default_factory=list)
    file_operations: List[Dict[str, str]] = field(default_factory=list)
    network_connections: List[Dict[str, str]] = field(default_factory=list)
    memory_injections: int = 0
    privilege_escalations: int = 0
    
    # Labels (for training)
    is_malware: bool = False
    malware_type: Optional[MalwareType] = None


@dataclass
class MalwareDetection:
    """Result of malware detection"""
    event_id: str
    process_name: str
    is_malware: bool
    confidence: float  # 0-1.0
    severity: MalwareSeverity
    malware_type: Optional[MalwareType]
    
    # Scoring details
    static_score: float
    behavioral_score: float
    anomaly_score: float
    
    # Top indicators
    top_indicators: List[str] = field(default_factory=list)
    
    timestamp: datetime = field(default_factory=datetime.now)
    model_version: str = ""


class StaticFeatureExtractor:
    """Extract static features from process events"""
    
    # Known malicious patterns
    MALICIOUS_COMMANDS = [
        r"powershell.*-nop",
        r"cmd.*\/c.*whoami",
        r"rundll32.*shell32",
        r"certutil.*-decode",
        r"bitsadmin",
        r"mshta",
        r"regsvcs",
        r"psexec",
        r"wmic.*process.*call.*create"
    ]
    
    MALICIOUS_PATHS = [
        r"\\temp\\",
        r"\\appdata\\",
        r"\\programdata\\",
        r"\\perflogs\\",
        r"\\$recycle"
    ]
    
    MALICIOUS_REGISTRY = [
        r"HKLM\\Software\\Microsoft\\Windows\\Run",
        r"HKCU\\Software\\Microsoft\\Windows\\Run",
        r"HKLM\\System\\CurrentControlSet\\Services",
        r"HKLM\\Software\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon"
    ]
    
    def __init__(self):
        self.scaler = StandardScaler()
    
    def extract_static_features(self, event: ProcessEvent) -> np.ndarray:
        """Extract static features"""
        features = []
        
        # Command line analysis
        cmd_features = self._analyze_command_line(event.command_line)
        features.extend(cmd_features)
        
        # Path analysis
        path_features = self._analyze_path(event.process_path)
        features.extend(path_features)
        
        # Process name analysis
        name_features = self._analyze_process_name(event.process_name)
        features.extend(name_features)
        
        # Parent process analysis
        parent_features = self._analyze_parent_process(event.parent_process_name)
        features.extend(parent_features)
        
        # File hash features (entropy indicator)
        hash_features = self._analyze_hashes(event.hash_md5, event.hash_sha256)
        features.extend(hash_features)
        
        return np.array(features[:20], dtype=np.float32)
    
    def _analyze_command_line(self, cmd_line: str) -> List[float]:
        """Analyze command line for malicious patterns"""
        features = []
        
        # Length
        features.append(float(len(cmd_line)))
        
        # Encoding/obfuscation indicators
        features.append(float(cmd_line.count("-enc")))
        features.append(float(cmd_line.count("encoding")))
        features.append(float(cmd_line.count("base64")))
        
        # Malicious pattern matches
        malicious_matches = sum(
            1 for pattern in self.MALICIOUS_COMMANDS
            if re.search(pattern, cmd_line, re.IGNORECASE)
        )
        features.append(float(malicious_matches))
        
        while len(features) < 6:
            features.append(0.0)
        
        return features[:6]
    
    def _analyze_path(self, path: str) -> List[float]:
        """Analyze file path"""
        features = []
        
        # Suspicious directory
        is_suspicious = any(
            re.search(pattern, path, re.IGNORECASE)
            for pattern in self.MALICIOUS_PATHS
        )
        features.append(1.0 if is_suspicious else 0.0)
        
        # System directory
        is_system = "system32" in path.lower() or "windows" in path.lower()
        features.append(1.0 if is_system else 0.0)
        
        # Depth
        depth = path.count("\\")
        features.append(float(min(depth, 10)))
        
        # Hidden file
        features.append(1.0 if "." in Path(path).name else 0.0)
        
        return features[:4]
    
    def _analyze_process_name(self, name: str) -> List[float]:
        """Analyze process name"""
        features = []
        
        # Known malware processes
        malware_processes = [
            "lsass", "svchost", "rundll32", "powershell",
            "cmd", "explorer", "winlogon", "csrss"
        ]
        
        is_suspicious = name.lower() in malware_processes
        features.append(1.0 if is_suspicious else 0.0)
        
        # Misspelled Windows processes
        has_typo = any(
            name.lower().startswith(proc[:-1]) and len(name) > len(proc)
            for proc in ["lsass", "svchost", "services"]
        )
        features.append(1.0 if has_typo else 0.0)
        
        # Unusual characters
        unusual_chars = sum(1 for c in name if not c.isalnum() and c not in ".-_")
        features.append(float(unusual_chars))
        
        return features[:3]
    
    def _analyze_parent_process(self, parent_name: str) -> List[float]:
        """Analyze parent process"""
        features = []
        
        # Suspicious parents
        suspicious_parents = ["explorer.exe", "svchost.exe", "winlogon.exe", "services.exe"]
        
        is_suspicious = parent_name.lower() in suspicious_parents
        features.append(1.0 if is_suspicious else 0.0)
        
        # Unknown parent
        is_unknown = parent_name == ""
        features.append(1.0 if is_unknown else 0.0)
        
        return features[:2]
    
    def _analyze_hashes(self, md5: str, sha256: str) -> List[float]:
        """Analyze file hashes"""
        features = []
        
        # Presence of hashes (valid binary)
        has_md5 = len(md5) > 0
        has_sha256 = len(sha256) > 0
        features.append(1.0 if (has_md5 and has_sha256) else 0.0)
        
        # Hash entropy indicator (simplified)
        features.append(1.0 if len(set(md5)) > 20 else 0.0)
        
        return features[:2]


class BehavioralFeatureExtractor:
    """Extract behavioral features from process events"""
    
    def extract_behavioral_features(self, event: ProcessEvent) -> np.ndarray:
        """Extract behavioral features"""
        features = []
        
        # Registry access analysis
        reg_features = self._analyze_registry_access(event.registry_accesses)
        features.extend(reg_features)
        
        # File operation analysis
        file_features = self._analyze_file_operations(event.file_operations)
        features.extend(file_features)
        
        # Network connection analysis
        net_features = self._analyze_network_connections(event.network_connections)
        features.extend(net_features)
        
        # Memory and privilege analysis
        mem_features = [
            float(event.memory_injections),
            float(event.privilege_escalations)
        ]
        features.extend(mem_features)
        
        return np.array(features[:12], dtype=np.float32)
    
    def _analyze_registry_access(self, accesses: List[str]) -> List[float]:
        """Analyze registry access patterns"""
        features = []
        
        # Count
        features.append(float(len(accesses)))
        
        # Malicious registry paths
        malicious_patterns = [
            r"HKLM\\Software\\Microsoft\\Windows\\Run",
            r"HKCU\\Software\\Microsoft\\Windows\\Run",
            r"Winlogon", "Services", "System\\CurrentControlSet"
        ]
        
        malicious_count = sum(
            1 for access in accesses
            for pattern in malicious_patterns
            if pattern.lower() in access.lower()
        )
        features.append(float(malicious_count))
        
        # Persistence mechanisms
        persistence_count = sum(
            1 for access in accesses
            if any(x in access.lower() for x in ["run", "startup", "userinit"])
        )
        features.append(float(persistence_count))
        
        while len(features) < 4:
            features.append(0.0)
        
        return features[:4]
    
    def _analyze_file_operations(self, operations: List[Dict[str, str]]) -> List[float]:
        """Analyze file operation patterns"""
        features = []
        
        # Total operations
        features.append(float(len(operations)))
        
        # Write operations (suspicious for malware)
        write_count = sum(
            1 for op in operations
            if op.get("operation", "").lower() == "write"
        )
        features.append(float(write_count))
        
        # System file modifications
        system_file_mods = sum(
            1 for op in operations
            if "system" in op.get("path", "").lower() or "windows" in op.get("path", "").lower()
        )
        features.append(float(system_file_mods))
        
        # Executable file operations
        exe_ops = sum(
            1 for op in operations
            if op.get("path", "").lower().endswith(".exe")
        )
        features.append(float(exe_ops))
        
        while len(features) < 5:
            features.append(0.0)
        
        return features[:5]
    
    def _analyze_network_connections(self, connections: List[Dict[str, str]]) -> List[float]:
        """Analyze network connection patterns"""
        features = []
        
        # Total connections
        features.append(float(len(connections)))
        
        # Known C2 ports
        c2_ports = [4444, 8888, 1337, 53, 25, 587]
        c2_connections = sum(
            1 for conn in connections
            if int(conn.get("port", 0)) in c2_ports
        )
        features.append(float(c2_connections))
        
        # External connections
        internal_ips = ["192.168", "10.", "172."]
        external_count = sum(
            1 for conn in connections
            if not any(conn.get("destination", "").startswith(ip) for ip in internal_ips)
        )
        features.append(float(external_count))
        
        while len(features) < 3:
            features.append(0.0)
        
        return features[:3]


class MalwareDetectionModel:
    """ML model for malware detection"""
    
    def __init__(self):
        self.static_forest = IsolationForest(contamination=0.1, random_state=42)
        self.behavioral_forest = IsolationForest(contamination=0.15, random_state=42)
        self.ensemble_model = RandomForestClassifier(n_estimators=50, random_state=42)
        
        self.static_extractor = StaticFeatureExtractor()
        self.behavioral_extractor = BehavioralFeatureExtractor()
        
        self.static_scaler = StandardScaler()
        self.behavioral_scaler = StandardScaler()
        
        self.version = "1.0.0"
        self.trained = False
        
        # Adaptive thresholds
        self.static_threshold = 0.6
        self.behavioral_threshold = 0.5
        self.anomaly_threshold = 0.65
    
    def train(self, events: List[ProcessEvent]) -> Dict[str, float]:
        """Train malware detection models"""
        logger.info(f"Training malware detector on {len(events)} events")
        
        static_features = np.array([
            self.static_extractor.extract_static_features(e) for e in events
        ])
        behavioral_features = np.array([
            self.behavioral_extractor.extract_behavioral_features(e) for e in events
        ])
        
        # Scale features
        static_features_scaled = self.static_scaler.fit_transform(static_features)
        behavioral_features_scaled = self.behavioral_scaler.fit_transform(behavioral_features)
        
        # Train anomaly detectors
        self.static_forest.fit(static_features_scaled)
        self.behavioral_forest.fit(behavioral_features_scaled)
        
        # Combine features for ensemble
        combined_features = np.hstack([static_features_scaled, behavioral_features_scaled])
        labels = np.array([int(e.is_malware) for e in events])
        
        # Train ensemble
        self.ensemble_model.fit(combined_features, labels)
        
        self.trained = True
        logger.info("Malware detector training complete")
        
        return {
            "events_trained": len(events),
            "malware_samples": sum(1 for e in events if e.is_malware),
            "clean_samples": sum(1 for e in events if not e.is_malware)
        }
    
    def detect(self, event: ProcessEvent) -> Tuple[float, float, float]:
        """Detect malware and return component scores"""
        if not self.trained:
            return 0.5, 0.5, 0.5
        
        # Extract features
        static_feat = self.static_extractor.extract_static_features(event).reshape(1, -1)
        behavioral_feat = self.behavioral_extractor.extract_behavioral_features(event).reshape(1, -1)
        
        # Scale
        static_feat_scaled = self.static_scaler.transform(static_feat)
        behavioral_feat_scaled = self.behavioral_scaler.transform(behavioral_feat)
        
        # Score with anomaly forests (convert to 0-1 range)
        static_score = 1.0 - (self.static_forest.score_samples(static_feat_scaled)[0] + 1) / 2
        behavioral_score = 1.0 - (self.behavioral_forest.score_samples(behavioral_feat_scaled)[0] + 1) / 2
        
        # Ensemble prediction
        combined_feat = np.hstack([static_feat_scaled, behavioral_feat_scaled])
        ensemble_proba = self.ensemble_model.predict_proba(combined_feat)[0]
        malware_prob = ensemble_proba[1]  # Probability of malware class
        
        # Anomaly score (combined)
        anomaly_score = (static_score + behavioral_score) / 2
        
        return float(static_score), float(behavioral_score), float(anomaly_score)
    
    def save(self, filepath: str):
        """Save model to disk"""
        import os
        os.makedirs(os.path.dirname(filepath) or '.', exist_ok=True)
        
        model_data = {
            'static_forest': self.static_forest,
            'behavioral_forest': self.behavioral_forest,
            'ensemble_model': self.ensemble_model,
            'static_scaler': self.static_scaler,
            'behavioral_scaler': self.behavioral_scaler,
            'static_threshold': self.static_threshold,
            'behavioral_threshold': self.behavioral_threshold,
            'anomaly_threshold': self.anomaly_threshold,
            'version': self.version,
            'trained': self.trained
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
        
        logger.info(f"Malware detection model saved to {filepath}")
    
    def load(self, filepath: str):
        """Load model from disk"""
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)
        
        self.static_forest = model_data['static_forest']
        self.behavioral_forest = model_data['behavioral_forest']
        self.ensemble_model = model_data['ensemble_model']
        self.static_scaler = model_data['static_scaler']
        self.behavioral_scaler = model_data['behavioral_scaler']
        self.static_threshold = model_data.get('static_threshold', 0.6)
        self.behavioral_threshold = model_data.get('behavioral_threshold', 0.5)
        self.anomaly_threshold = model_data.get('anomaly_threshold', 0.65)
        self.version = model_data.get('version', '1.0.0')
        self.trained = model_data.get('trained', True)
        
        logger.info(f"Malware detection model loaded from {filepath}")


class MalwareDetector:
    """Main malware detection system"""
    
    def __init__(self):
        self.model = MalwareDetectionModel()
        self.detection_history = deque(maxlen=5000)
        self.lock = threading.RLock()
        self.models_dir = Path("ml/models/malware_detection")
        self.models_dir.mkdir(parents=True, exist_ok=True)
    
    async def detect_process(self, event: ProcessEvent) -> MalwareDetection:
        """Detect malware in a process"""
        static_score, behavioral_score, anomaly_score = self.model.detect(event)
        
        # Determine if malware
        is_malware = anomaly_score > self.model.anomaly_threshold
        
        # Overall confidence
        confidence = anomaly_score
        
        # Determine severity
        severity = self._determine_severity(confidence)
        
        # Determine malware type (simplified)
        malware_type = self._determine_malware_type(event) if is_malware else None
        
        # Collect indicators
        indicators = self._get_indicators(event, static_score, behavioral_score)
        
        detection = MalwareDetection(
            event_id=event.event_id,
            process_name=event.process_name,
            is_malware=is_malware,
            confidence=confidence,
            severity=severity,
            malware_type=malware_type,
            static_score=static_score,
            behavioral_score=behavioral_score,
            anomaly_score=anomaly_score,
            top_indicators=indicators,
            model_version=self.model.version
        )
        
        with self.lock:
            self.detection_history.append(detection)
        
        if is_malware:
            logger.warning(f"Malware detected: {event.process_name} ({confidence:.0%})")
        
        return detection
    
    def _determine_severity(self, confidence: float) -> MalwareSeverity:
        """Determine malware severity"""
        if confidence > 0.9:
            return MalwareSeverity.CRITICAL
        elif confidence > 0.8:
            return MalwareSeverity.HIGH
        elif confidence > 0.7:
            return MalwareSeverity.MEDIUM
        elif confidence > 0.6:
            return MalwareSeverity.LOW
        else:
            return MalwareSeverity.SUSPICIOUS
    
    def _determine_malware_type(self, event: ProcessEvent) -> Optional[MalwareType]:
        """Determine malware type"""
        # Simplified logic based on behavior
        if event.privilege_escalations > 0:
            return MalwareType.ROOTKIT
        elif any("bitcoin" in x.lower() or "crypto" in x.lower() for x in event.registry_accesses):
            return MalwareType.SPYWARE
        elif any(".encrypted" in f.get("path", "") for f in event.file_operations):
            return MalwareType.RANSOMWARE
        elif event.memory_injections > 0:
            return MalwareType.TROJAN
        else:
            return MalwareType.UNKNOWN
    
    def _get_indicators(self, event: ProcessEvent, static_score: float, behavioral_score: float) -> List[str]:
        """Get top indicators"""
        indicators = []
        
        if static_score > 0.7:
            indicators.append(f"High static score ({static_score:.0%})")
        if behavioral_score > 0.7:
            indicators.append(f"High behavioral score ({behavioral_score:.0%})")
        if event.privilege_escalations > 0:
            indicators.append(f"Privilege escalation attempts ({event.privilege_escalations})")
        if event.memory_injections > 0:
            indicators.append(f"Memory injections detected ({event.memory_injections})")
        if len(event.network_connections) > 5:
            indicators.append(f"Excessive network connections ({len(event.network_connections)})")
        
        return indicators[:3]  # Top 3
    
    async def get_statistics(self) -> Dict[str, Any]:
        """Get detection statistics"""
        with self.lock:
            total_detections = len(self.detection_history)
            malware_count = sum(1 for d in self.detection_history if d.is_malware)
            
            severity_counts = defaultdict(int)
            type_counts = defaultdict(int)
            
            for detection in self.detection_history:
                severity_counts[detection.severity.value] += 1
                if detection.malware_type:
                    type_counts[detection.malware_type.value] += 1
        
        return {
            "total_processes_scanned": total_detections,
            "malware_detected": malware_count,
            "clean_processes": total_detections - malware_count,
            "detection_rate": malware_count / total_detections if total_detections > 0 else 0,
            "by_severity": dict(severity_counts),
            "by_type": dict(type_counts)
        }


# Global instance
_detector_instance = None


def get_malware_detector() -> MalwareDetector:
    """Get or create malware detector"""
    global _detector_instance
    if _detector_instance is None:
        _detector_instance = MalwareDetector()
    return _detector_instance
